import asyncio
import os
from typing import AsyncGenerator, List

import streamlit as st
from streamlit.runtime.scriptrunner import get_script_run_ctx
from client import AgentClient
from schema import ChatMessage


# A Streamlit app for interacting with the langgraph agent via a simple chat interface.
# The app has three main functions which are all run async:

# - main() - sets up the streamlit app and high level structure
# - draw_messages() - draws a set of chat messages - either replaying existing messages
#   or streaming new ones.
# - handle_feedback() - Draws a feedback widget and records feedback from the user.

# The app heavily uses AgentClient to interact with the agent's FastAPI endpoints.


APP_TITLE = "Agent Service Toolkit"
APP_ICON = "ğŸ§°"

@st.cache_resource
def get_agent_client():
    agent_url = os.getenv("AGENT_URL", "http://localhost")
    return AgentClient(agent_url)


async def main():
    st.set_page_config(
        page_title=APP_TITLE,
        page_icon=APP_ICON,
        menu_items={},
    )

    # Hide the streamlit upper-right chrome
    st.html(
        """
        <style>
        [data-testid="stStatusWidget"] {
                visibility: hidden;
                height: 0%;
                position: fixed;
            }
        </style>
        """,
    )
    if st.get_option("client.toolbarMode") != "minimal":
        st.set_option("client.toolbarMode", "minimal")
        await asyncio.sleep(0.1)
        st.rerun()

    models = {
        "OpenAI GPT-4o-mini (streaming)": "gpt-4o-mini",
        "llama-3.1-70b on Groq": "llama-3.1-70b",
    }
    # Config options
    with st.sidebar:
        st.header(f"{APP_ICON} {APP_TITLE}")
        ""
        "Full toolkit for running an AI agent service built with LangGraph, FastAPI and Streamlit"
        with st.popover(":material/settings: Settings", use_container_width=True):
            m = st.radio("LLM to use", options=models.keys())
            model = models[m]
            use_streaming = st.toggle("Stream results", value=True)

        @st.dialog("Architecture")
        def architecture_dialog():
            st.image("https://github.com/JoshuaC215/agent-service-toolkit/blob/main/media/agent_architecture.png?raw=true")
            "[View full size on Github](https://github.com/JoshuaC215/agent-service-toolkit/blob/main/media/agent_architecture.png)"
            st.caption("App hosted on [Streamlit Cloud](https://share.streamlit.io/) with FastAPI service running in [Azure](https://learn.microsoft.com/en-us/azure/app-service/)")

        if st.button(":material/schema: Architecture", use_container_width=True):
            architecture_dialog()

        with st.popover(":material/policy: Privacy", use_container_width=True):
            st.write("Prompts, responses and feedback in this app are anonymously recorded and saved to LangSmith for product evaluation and improvement purposes only.")

        "[View the source code](https://github.com/JoshuaC215/agent-service-toolkit)"
        st.caption("Made with :material/favorite: by [Joshua](https://www.linkedin.com/in/joshua-k-carroll/) in Oakland")

    # Draw existing messages
    if "messages" not in st.session_state:
        st.session_state.messages = []
    messages: List[ChatMessage] = st.session_state.messages

    if len(messages) == 0:
        WELCOME = "Hello! I'm an AI-powered research assistant with web search and a calculator. I may take a few seconds to boot up when you send your first message. Ask me anything!"
        with st.chat_message("ai"):
            st.write(WELCOME)

    # draw_messages() expects an async iterator over messages
    async def amessage_iter():
        for m in messages: yield m
    await draw_messages(amessage_iter())

    # Generate new message if the user provided new input
    if input := st.chat_input():
        messages.append(ChatMessage(type="human", content=input))
        st.chat_message("human").write(input)
        agent_client = get_agent_client()
        if use_streaming:
            stream = agent_client.astream(
                message=input,
                model=model,
                thread_id=get_script_run_ctx().session_id,
            )
            await draw_messages(stream, is_new=True)
        else:
            response = await agent_client.ainvoke(
                message=input,
                model=model,
                thread_id=get_script_run_ctx().session_id,
            )
            messages.append(response)
            st.chat_message("ai").write(response.content)
        st.rerun() # Clear stale containers

    # If messages have been generated, show feedback widget
    if len(messages) > 0:
        with st.session_state.last_message:
            await handle_feedback()


async def draw_messages(
        messages_agen: AsyncGenerator[ChatMessage | str, None],
        is_new=False,
    ):
    """
    ç»˜åˆ¶ä¸€ç»„èŠå¤©æ¶ˆæ¯ï¼Œå¯ä»¥æ˜¯é‡æ”¾ç°æœ‰æ¶ˆæ¯æˆ–æµå¼ä¼ è¾“æ–°æ¶ˆæ¯ã€‚

    æ­¤å‡½æ•°å…·æœ‰å¤„ç†æµå¼ä»¤ç‰Œå’Œå·¥å…·è°ƒç”¨çš„é™„åŠ é€»è¾‘ã€‚
    - ä½¿ç”¨å ä½ç¬¦å®¹å™¨æ¥æ¸²æŸ“å®æ—¶æµå¼ä»¤ç‰Œã€‚
    - ä½¿ç”¨çŠ¶æ€å®¹å™¨æ¥æ¸²æŸ“å·¥å…·è°ƒç”¨ã€‚è·Ÿè¸ªå·¥å…·è¾“å…¥å’Œè¾“å‡ºï¼Œå¹¶ç›¸åº”æ›´æ–°çŠ¶æ€å®¹å™¨ã€‚

    æ­¤å‡½æ•°è¿˜éœ€è¦åœ¨ä¼šè¯çŠ¶æ€ä¸­è·Ÿè¸ªæœ€åä¸€æ¡æ¶ˆæ¯å®¹å™¨ï¼Œå› ä¸ºåç»­æ¶ˆæ¯å¯ä»¥ç»˜åˆ¶åˆ°åŒä¸€å®¹å™¨ä¸­ã€‚
    è¿™ä¹Ÿç”¨äºåœ¨æœ€æ–°èŠå¤©æ¶ˆæ¯ä¸­ç»˜åˆ¶åé¦ˆå°éƒ¨ä»¶ã€‚

    å‚æ•°:
        messages_aiter: ä¸€ä¸ªå¼‚æ­¥è¿­ä»£å™¨ï¼Œæä¾›è¦ç»˜åˆ¶çš„æ¶ˆæ¯ã€‚
        is_new: æ¶ˆæ¯æ˜¯å¦ä¸ºæ–°æ¶ˆæ¯ã€‚
    """

    # è·Ÿè¸ªæœ€åä¸€æ¡æ¶ˆæ¯ç±»å‹
    last_message_type = None
    st.session_state.last_message = None    # åˆå§‹åŒ–æœ€åä¸€æ¡æ¶ˆæ¯

    # ç”¨äºä¸­é—´æµå¼ä»¤ç‰Œçš„å ä½ç¬¦
    streaming_content = ""
    streaming_placeholder = None    # æµå¼å ä½ç¬¦

    # è¿­ä»£æ¶ˆæ¯å¹¶ç»˜åˆ¶å®ƒä»¬
    while msg := await anext(messages_agen, None):
        # str æ¶ˆæ¯è¡¨ç¤ºæ­£åœ¨æµå¼ä¼ è¾“çš„ä¸­é—´ä»¤ç‰Œ
        if isinstance(msg, str):
            # å¦‚æœå ä½ç¬¦ä¸ºç©ºï¼Œè¿™æ˜¯æ–°æ¶ˆæ¯çš„ç¬¬ä¸€ä¸ªä»¤ç‰Œ
            # éœ€è¦è¿›è¡Œåˆå§‹åŒ–ã€‚
            if not streaming_placeholder:
                if last_message_type != "ai":
                    last_message_type = "ai"
                    st.session_state.last_message = st.chat_message("ai")   # åˆ›å»º AI æ¶ˆæ¯å®¹å™¨
                with st.session_state.last_message:
                    streaming_placeholder = st.empty()  # åˆ›å»ºå ä½ç¬¦

            streaming_content += msg    # æ·»åŠ æµå¼å†…å®¹
            streaming_placeholder.write(streaming_content)  # æ›´æ–°å ä½ç¬¦å†…å®¹
            continue
        # æ£€æŸ¥æ¶ˆæ¯ç±»å‹æ˜¯å¦ä¸º ChatMessage
        if not isinstance(msg, ChatMessage):
            st.error(f"Unexpected message type: {type(msg)}")   # å¤„ç†æ„å¤–æ¶ˆæ¯ç±»å‹
            st.write(msg)
            st.stop()
        match msg.type:     # æ ¹æ®æ¶ˆæ¯ç±»å‹è¿›è¡ŒåŒ¹é…
            # æ¥è‡ªç”¨æˆ·çš„æ¶ˆæ¯ï¼Œæœ€ç®€å•çš„æƒ…å†µ
            case "human":
                last_message_type = "human"
                st.chat_message("human").write(msg.content)     # ç»˜åˆ¶äººç±»æ¶ˆæ¯

            # æ¥è‡ªä»£ç†çš„æ¶ˆæ¯æ˜¯æœ€å¤æ‚çš„æƒ…å†µï¼Œéœ€è¦å¤„ç†æµå¼ä»¤ç‰Œå’Œå·¥å…·è°ƒç”¨
            case "ai":
                # å¦‚æœæ˜¯æ–°æ¶ˆæ¯ï¼Œå°†æ¶ˆæ¯å­˜å‚¨åœ¨ä¼šè¯çŠ¶æ€ä¸­
                if is_new:
                    st.session_state.messages.append(msg)

                # å¦‚æœæœ€åä¸€æ¡æ¶ˆæ¯ç±»å‹ä¸æ˜¯ AIï¼Œåˆ›å»ºæ–°çš„èŠå¤©æ¶ˆæ¯
                if last_message_type != "ai":
                    last_message_type = "ai"
                    st.session_state.last_message = st.chat_message("ai")

                with st.session_state.last_message:
                    # å¦‚æœæ¶ˆæ¯æœ‰å†…å®¹ï¼Œå†™å‡ºå†…å®¹ã€‚
                    # é‡ç½®æµå¼å˜é‡ä»¥å‡†å¤‡ä¸‹ä¸€æ¡æ¶ˆæ¯ã€‚
                    if msg.content:
                        if streaming_placeholder:
                            streaming_placeholder.write(msg.content)    # æ›´æ–°å†…å®¹
                            streaming_content = ""  # é‡ç½®æµå¼å†…å®¹
                            streaming_placeholder = None    # æ¸…é™¤å ä½ç¬¦
                        else:
                            st.write(msg.content)   # å¦‚æœæ²¡æœ‰å ä½ç¬¦ï¼Œç›´æ¥å†™å†…å®¹

                    if msg.tool_calls:
                        # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
                        # ä¸ºæ¯ä¸ªå·¥å…·è°ƒç”¨åˆ›å»ºçŠ¶æ€å®¹å™¨ï¼Œå¹¶æŒ‰ ID å­˜å‚¨çŠ¶æ€å®¹å™¨ï¼Œä»¥ç¡®ä¿ç»“æœæ˜ å°„åˆ°æ­£ç¡®çš„çŠ¶æ€å®¹å™¨ã€‚
                        call_results = {}
                        for tool_call in msg.tool_calls:
                            status = st.status(
                                    f"""Tool Call: {tool_call["name"]}""",
                                    state="running" if is_new else "complete",
                                )
                            call_results[tool_call["id"]] = status  # å­˜å‚¨çŠ¶æ€å®¹å™¨
                            status.write("Input:")  # å†™å…¥å·¥å…·è°ƒç”¨è¾“å…¥
                            status.write(tool_call["args"])

                        # å¯¹äºæ¯ä¸ªå·¥å…·è°ƒç”¨ï¼ŒæœŸæœ›ä¸€ä¸ª ToolMessage
                        for _ in range(len(call_results)):
                            tool_result: ChatMessage = await anext(messages_agen)   # è·å–å·¥å…·ç»“æœæ¶ˆæ¯
                            if not tool_result.type == "tool":
                                st.error(f"Unexpected ChatMessage type: {tool_result.type}")    # å¤„ç†æ„å¤–æ¶ˆæ¯ç±»å‹
                                st.write(tool_result)
                                st.stop()

                            # å¦‚æœæ˜¯æ–°æ¶ˆæ¯ï¼Œè®°å½•æ¶ˆæ¯ï¼Œå¹¶æ›´æ–°æ­£ç¡®çš„çŠ¶æ€å®¹å™¨ä»¥æ˜¾ç¤ºç»“æœ
                            if is_new:
                                st.session_state.messages.append(tool_result)
                            status = call_results[tool_result.tool_call_id]     # è·å–å¯¹åº”çŠ¶æ€å®¹å™¨
                            status.write("Output:")     # å†™å…¥è¾“å‡º
                            status.write(tool_result.content)   # æ›´æ–°è¾“å‡ºå†…å®¹
                            status.update(state="complete")     # æ›´æ–°çŠ¶æ€ä¸ºå®Œæˆ

            # å¤„ç†æ„å¤–æ¶ˆæ¯ç±»å‹ï¼Œè®°å½•é”™è¯¯å¹¶åœæ­¢
            case _:
                st.error(f"Unexpected ChatMessage type: {msg.type}")
                st.write(msg)
                st.stop()


async def handle_feedback():
    """Draws a feedback widget and records feedback from the user."""

    # Keep track of last feedback sent to avoid sending duplicates
    if "last_feedback" not in st.session_state:
        st.session_state.last_feedback = (None, None)

    latest_run_id = st.session_state.messages[-1].run_id
    feedback = st.feedback("stars", key=latest_run_id)

    # If the feedback value or run ID has changed, send a new feedback record
    if feedback and (latest_run_id, feedback) != st.session_state.last_feedback:

        # Normalize the feedback value (an index) to a score between 0 and 1
        normalized_score = (feedback + 1) / 5.0

        agent_client = get_agent_client()
        await agent_client.acreate_feedback(
            run_id=latest_run_id,
            key="human-feedback-stars",
            score=normalized_score,
            kwargs=dict(
                comment="In-line human feedback",
            ),
        )
        st.session_state.last_feedback = (latest_run_id, feedback)
        st.toast("Feedback recorded", icon=":material/reviews:")


if __name__ == "__main__":
    asyncio.run(main())
